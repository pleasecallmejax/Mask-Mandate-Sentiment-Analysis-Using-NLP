{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First bring in the necessary import statements to EDA and initial modeling to examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jax/Documents/Flatiron\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import texthero as hr\n",
    "from PIL import Image \n",
    "from wordcloud import WordCloud\n",
    "from nltk import pos_tag, FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import defaultdict\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize, RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix, confusion_matrix, classification_report, accuracy_score, precision_score\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.setrecursionlimit(100000)\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model I'd like to use a count vectorizer and good ole logistic regression. Then I'll use naive bayes which is particularly successful with nlp because it assumes *naively* there is no interdependence amongst the variables. Also Multinomial Bayes allows me to train my model with less data and potentionally mislabeled data. So first let's split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = pd.read_csv('data/modeling_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unique_df['target'].copy()\n",
    "X = unique_df.drop(columns=['target','existence_confidence'], axis=1).copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=1, stratify=y)\n",
    "X_t, X_val, y_t, y_val = train_test_split(X, y, test_size=.25, random_state=2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150    1\n",
       "324     2\n",
       "5406    0\n",
       "914     1\n",
       "468     1\n",
       "       ..\n",
       "3120    2\n",
       "2163    1\n",
       "3099    1\n",
       "955     1\n",
       "3042    0\n",
       "Name: target, Length: 4110, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get to modeling. First let's test out using SMOTE to eliminate our class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_features_check(n):\n",
    "\n",
    "#     train_docs = [doc_preparer(doc) for doc in X_train['processedtwitter']]\n",
    "#     test_docs = [doc_preparer(doc) for doc in X_test['processedtwitter']]\n",
    "\n",
    "    # Secondary train-test split to build our best model\n",
    "    X_t, X_val, y_t, y_val = train_test_split(train_docs, y_train,\n",
    "                                              test_size=0.25, random_state=42)\n",
    "    # here's where our 'n' comes in\n",
    "    cv = CountVectorizer(max_features=n)\n",
    "\n",
    "    X_t_vec = cv.fit_transform(X_t)\n",
    "    X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "    X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "    X_t_vec.set_index(y_t.index, inplace=True)\n",
    "\n",
    "    # We then transform the validation set. (Do not refit the vectorizer!)\n",
    "\n",
    "    X_val_vec = cv.transform(X_val)\n",
    "    X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "    X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "    X_val_vec.set_index(y_val.index, inplace=True)\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "\n",
    "    mnb.fit(X_t_vec, y_t)\n",
    "    y_hat = mnb.predict(X_val_vec)\n",
    "    \n",
    "    \n",
    "    return accuracy_score(y_val, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_params= {\n",
    "'count__decode_error':['ignore', 'replace'],\n",
    "'count__analyzer' : ['word', 'char', 'char_wb'],\n",
    "'model__solver' : ['sag', 'saga'],\n",
    "'model__max_iter' :[4000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_pipe = imbPipeline([('count', CountVectorizer()),('sm', SMOTE()),('model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_gs = GridSearchCV(imb_pipe, param_grid=imb_params, cv = 5, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "imbmodel = imb_gs.fit(X_train['lemmed_tweets'].values.astype('U'), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tThe Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       766\n",
      "           1       0.94      0.93      0.94      2100\n",
      "           2       0.90      0.90      0.90      1244\n",
      "\n",
      "    accuracy                           0.92      4110\n",
      "   macro avg       0.91      0.92      0.92      4110\n",
      "weighted avg       0.92      0.92      0.92      4110\n",
      "\n",
      "\n",
      "\t\tThe Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.59      0.54       256\n",
      "           1       0.73      0.63      0.68       700\n",
      "           2       0.52      0.56      0.54       415\n",
      "\n",
      "    accuracy                           0.60      1371\n",
      "   macro avg       0.58      0.60      0.58      1371\n",
      "weighted avg       0.62      0.60      0.61      1371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imb_best = imbmodel.best_estimator_\n",
    "\n",
    "imby_trn_pred = imb_best.predict(X_train['lemmed_tweets'].values.astype('U'))\n",
    "imby_tst_pred = imb_best.predict(X_test['lemmed_tweets'].values.astype('U'))\n",
    "\n",
    "    \n",
    "print('\\t\\tThe Train Results')\n",
    "print(classification_report(y_train, imby_trn_pred))\n",
    "print('\\n\\t\\tThe Test Results')\n",
    "print(classification_report(y_test, imby_tst_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, we have not bad results but definitely overfit and not our best. Since we used SMOTE to address the class imbalnce, ideally now we would focus on accuracy since false negatives and positives bear the same weight. Now let's try it without SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params= {\n",
    "'count__decode_error':['strict', 'ignore', 'replace'],\n",
    "'count__analyzer' : ['word', 'char', 'char_wb'],\n",
    "'count__max_df' : [.95],\n",
    "'count__min_df' : [.05],\n",
    "'model__solver' : ['lbfgs','sag', 'saga'],\n",
    "'model__max_iter' :[4000]}\n",
    "    \n",
    "\n",
    "first_pipe = Pipeline([('count', CountVectorizer()),\n",
    "                    ('model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gs = GridSearchCV(first_pipe, param_grid=cv_params, cv = 5, verbose = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "lrmodel = cv_gs.fit(X_train['lemmed_tweets'].values.astype('U'), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tThe Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.06      0.10       766\n",
      "           1       0.53      0.95      0.68      2100\n",
      "           2       0.50      0.09      0.15      1244\n",
      "\n",
      "    accuracy                           0.52      4110\n",
      "   macro avg       0.49      0.37      0.31      4110\n",
      "weighted avg       0.50      0.52      0.41      4110\n",
      "\n",
      "\n",
      "\t\tThe Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.06      0.11       256\n",
      "           1       0.53      0.94      0.67       700\n",
      "           2       0.43      0.08      0.13       415\n",
      "\n",
      "    accuracy                           0.52      1371\n",
      "   macro avg       0.45      0.36      0.31      1371\n",
      "weighted avg       0.47      0.52      0.41      1371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_best = lrmodel.best_estimator_\n",
    "\n",
    "fy_trn_pred = lr_best.predict(X_train['lemmed_tweets'].values.astype('U'))\n",
    "fy_tst_pred = lr_best.predict(X_test['lemmed_tweets'].values.astype('U'))\n",
    "\n",
    "    \n",
    "print('\\t\\tThe Train Results')\n",
    "print(classification_report(y_train, fy_trn_pred))\n",
    "print('\\n\\t\\tThe Test Results')\n",
    "print(classification_report(y_test, fy_tst_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holy cajolly wildly overfit to training buuuut a start. Now for my random forest classifier search it took a bit of time as well so be fair warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Param setup for Gridsearch\n",
    "tf_params = {\n",
    " 'tf__max_features':[100, 500, 2000, None],\n",
    " 'tf__ngram_range': [(1, 1), (1, 2), (2, 2), None],\n",
    " 'mnb__alpha': [.1, .5, .8, 1],\n",
    " 'mnb__fit_prior': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_pipe = Pipeline([('tf', TfidfVectorizer()),\n",
    "                    ('mnb', MultinomialNB())])\n",
    "mnb_gs = GridSearchCV(mnb_pipe, param_grid=tf_params, cv = 5, verbose = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.58807786 0.586618   0.55596107        nan 0.62068127 0.62068127\n",
      " 0.56618005        nan 0.62919708 0.63163017 0.58199513        nan\n",
      " 0.63211679 0.63406326 0.61216545        nan 0.46593674 0.46739659\n",
      " 0.27664234        nan 0.57664234 0.57493917 0.35523114        nan\n",
      " 0.60389294 0.60389294 0.43260341        nan 0.63284672 0.63576642\n",
      " 0.54476886        nan 0.58759124 0.58759124 0.55620438        nan\n",
      " 0.62214112 0.62189781 0.56836983        nan 0.63527981 0.63625304\n",
      " 0.58783455        nan 0.62773723 0.62773723 0.61119221        nan\n",
      " 0.46545012 0.46739659 0.27639903        nan 0.57493917 0.57712895\n",
      " 0.35717762        nan 0.61435523 0.60632603 0.43698297        nan\n",
      " 0.63187348 0.64817518 0.54841849        nan 0.58807786 0.58856448\n",
      " 0.55717762        nan 0.62214112 0.61849148 0.56788321        nan\n",
      " 0.63284672 0.63041363 0.5892944         nan 0.61922141 0.61873479\n",
      " 0.61046229        nan 0.46618005 0.46569343 0.27615572        nan\n",
      " 0.57737226 0.57688564 0.35766423        nan 0.61459854 0.60900243\n",
      " 0.44014599        nan 0.64038929 0.64963504 0.54939173        nan\n",
      " 0.58832117 0.58832117 0.55620438        nan 0.61922141 0.61532847\n",
      " 0.5676399         nan 0.6296837  0.62481752 0.59026764        nan\n",
      " 0.61240876 0.61119221 0.60486618        nan 0.46666667 0.46642336\n",
      " 0.27615572        nan 0.57712895 0.57688564 0.35815085        nan\n",
      " 0.61557178 0.61046229 0.44087591        nan 0.64257908 0.64939173\n",
      " 0.54963504        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mnb_model = mnb_gs.fit(X_train['lemmed_tweets'].values.astype('U'), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tThe Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       766\n",
      "           1       0.94      0.93      0.94      2100\n",
      "           2       0.89      0.89      0.89      1244\n",
      "\n",
      "    accuracy                           0.92      4110\n",
      "   macro avg       0.91      0.92      0.91      4110\n",
      "weighted avg       0.92      0.92      0.92      4110\n",
      "\n",
      "\n",
      "\t\tThe Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55       256\n",
      "           1       0.72      0.78      0.75       700\n",
      "           2       0.61      0.58      0.59       415\n",
      "\n",
      "    accuracy                           0.67      1371\n",
      "   macro avg       0.64      0.62      0.63      1371\n",
      "weighted avg       0.66      0.67      0.66      1371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb_best = mnb_model.best_estimator_\n",
    "\n",
    "mnby_trn_pred = mnb_best.predict(X_train['lemmed_tweets'].values.astype('U'))\n",
    "mnby_tst_pred = mnb_best.predict(X_test['lemmed_tweets'].values.astype('U'))\n",
    "\n",
    "\n",
    "    \n",
    "print('\\t\\tThe Train Results')\n",
    "print(classification_report(y_train, mnby_trn_pred))\n",
    "print('\\n\\t\\tThe Test Results')\n",
    "print(classification_report(y_test, mnby_tst_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    " 'tf__ngram_range': [(1, 2)],\n",
    " 'tf__max_features':[100, 500, 2000, None],\n",
    " 'tf__ngram_range': [(1, 1), (1, 2), (2, 2), None],\n",
    " 'tf__min_df':[.05, None],\n",
    " 'tf__max_df':[.95, None],\n",
    " 'tf__stop_words': [None, 'english'],\n",
    " 'rf__max_depth': [100, 500, 1000],\n",
    " 'rf__min_samples_split': [100],\n",
    " 'rf__max_leaf_nodes': [None]}\n",
    "\n",
    "rf_pipe = Pipeline([('tf',  TfidfVectorizer()),\n",
    "                     ('rf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 384 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.51094891 0.51094891 0.51094891 0.51094891        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.51094891 0.51094891\n",
      " 0.51094891 0.51094891        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.51094891 0.51094891 0.51094891 0.51094891\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.51094891 0.51094891 0.51094891 0.51094891        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.51094891 0.51094891 0.51094891 0.51094891\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.51094891 0.51094891 0.51094891 0.51094891        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.51094891 0.51094891\n",
      " 0.51094891 0.51094891        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.51094891 0.51094891 0.51094891 0.51094891\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.51094891 0.51094891\n",
      " 0.51094891 0.51094891        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.51094891 0.51094891 0.51094891 0.51094891\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.51094891 0.51094891 0.51094891 0.51094891        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.51094891 0.51094891\n",
      " 0.51094891 0.51094891        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_gs = GridSearchCV(rf_pipe, param_grid=rf_params, cv = 5, verbose = 1, n_jobs = -1)\n",
    "rf_model = rf_gs.fit(X_train['lemmed_tweets'].values.astype('U'), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tThe Train Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       766\n",
      "           1       0.51      1.00      0.68      2100\n",
      "           2       0.00      0.00      0.00      1244\n",
      "\n",
      "    accuracy                           0.51      4110\n",
      "   macro avg       0.17      0.33      0.23      4110\n",
      "weighted avg       0.26      0.51      0.35      4110\n",
      "\n",
      "\n",
      "\t\tThe Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       256\n",
      "           1       0.51      1.00      0.68       700\n",
      "           2       0.00      0.00      0.00       415\n",
      "\n",
      "    accuracy                           0.51      1371\n",
      "   macro avg       0.17      0.33      0.23      1371\n",
      "weighted avg       0.26      0.51      0.35      1371\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rfy_trn_pred = rf_model.predict(X_train['lemmed_tweets'].values.astype('U'))\n",
    "rfy_tst_pred = rf_model.predict(X_test['lemmed_tweets'].values.astype('U'))\n",
    "    \n",
    "print('\\t\\tThe Train Results')\n",
    "print(classification_report(y_train, rfy_trn_pred))\n",
    "print('\\n\\t\\tThe Test Results')\n",
    "print(classification_report(y_test, rfy_tst_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 256,   0],\n",
       "       [  0, 700,   0],\n",
       "       [  0, 415,   0]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, rfy_tst_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have picked the best model lets get to vectorizing and our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on X_train[\"text\"] and transform it\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "X_train_vectorized = tfidf.fit_transform(X_train['lemmed_tweets'].values.astype('U'))\n",
    "Xtv_df = pd.DataFrame(X_train_vectorized.toarray(), columns=tfidf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_values = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_vec = tfidf.fit_transform(X_train['lemmed_tweets'].values.astype('U'))\n",
    "X_t_vec = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(tfidf.vocabulary_)\n",
    "X_t_vec.set_index(y_t.index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vec = tfidf.transform(X_val)\n",
    "X_val_vec = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(tfidf.vocabulary_)\n",
    "#X_val_vec.set_index(y_val.index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-87d68f1cf581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m tf_nb_pipe = Pipeline([\n\u001b[1;32m      6\u001b[0m     ('tfidf', TfidfVectorizer(stop_words=stopwords, \n\u001b[0;32m----> 7\u001b[0;31m                               \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                               \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m85000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                              ngram_range=(1,3))),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "tf_nb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords, \n",
    "                              tokenizer=tokenize, \n",
    "                              max_df=0.25, max_features=85000,\n",
    "                             ngram_range=(1,3))),\n",
    "    ('smt', SMOTE(random_state=42)),\n",
    "    ('mnb', MultinomialNB(alpha=0.005)),\n",
    "])\n",
    "\n",
    "tf_nb_pipe.fit(train_docs, y_train)\n",
    "\n",
    "\n",
    "y_trn_pred = tf_nb_pipe.predict(train_docs)\n",
    "y_tst_pred = tf_nb_pipe.predict(test_docs)\n",
    "    \n",
    "print('\\t\\tThe Train Results')\n",
    "print(classification_report(y_train, y_trn_pred))\n",
    "print('\\n\\t\\tThe Test Results')\n",
    "print(classification_report(y_test, y_tst_pred))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1371, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d1031034809b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1371, 2]"
     ]
    }
   ],
   "source": [
    "y_pred=mnb.predict(X_val_vec)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_hat = mnb.predict(X_val_vec)\n",
    "#print(f1_score(y_val, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train,y_train)\n",
    "#y_pred=model.predict(X_test)\n",
    "#print(accuracy_score(y_test,y_pred))\n",
    "#print(X_train.toarray()[:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
